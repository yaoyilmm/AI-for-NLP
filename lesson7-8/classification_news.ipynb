{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true_news_label len = 5000\n",
      "fake_news_label len = 5001\n",
      "总的数据量: 10001\n",
      "样本之一: 北京售票员可厉害，嘿嘿，有专座的，会直接拉着脖子指着鼻子让上面的人站起来让 座的，呵呵，比较赞。。。 杭州就是很少有人给让座，除非司机要求乘客那样做。 五一去杭州一个景点玩，车上有两个不到一岁的小孩，就是没有人给让座，没办法家长只能在车上把小孩的推车打开让孩子坐进去，但是孩子还是闹，只能抱着，景点离市区很远，车上很颠，最后家长坐在地上抱孩子，就是没有一个人给让座，要是在北京，一上车就有人让座了\n",
      "\n",
      "样本的label: 1.0\n",
      "实际类型:labels[4999]= 新华社 labels[10000]= 其他新闻报道单位\n",
      "7000 7000\n",
      "3001 3001\n",
      "准确率为： 0.9886704431856048\n",
      "基于词袋模型特征的KNN模型\n",
      "准确率: 0.75\n",
      "精度: 0.84\n",
      "召回率: 0.75\n",
      "F1得分: 0.74\n",
      "基于词袋模型特征的贝叶斯分类器\n",
      "准确率: 0.99\n",
      "精度: 0.99\n",
      "召回率: 0.99\n",
      "F1得分: 0.99\n",
      "[0. 1. 1. ... 0. 1. 0.]\n",
      "基于词袋模型特征的逻辑回归\n",
      "准确率: 0.99\n",
      "精度: 0.99\n",
      "召回率: 0.99\n",
      "F1得分: 0.99\n",
      "基于词袋模型的支持向量机\n",
      "准确率: 0.99\n",
      "精度: 0.99\n",
      "召回率: 0.99\n",
      "F1得分: 0.99\n",
      "基于tfidf的KNN模型\n",
      "准确率: 0.65\n",
      "精度: 0.8\n",
      "召回率: 0.65\n",
      "F1得分: 0.61\n",
      "基于tfidf的朴素贝叶斯模型\n",
      "准确率: 0.99\n",
      "精度: 0.99\n",
      "召回率: 0.99\n",
      "F1得分: 0.99\n",
      "基于tfidf的逻辑回归模型\n",
      "准确率: 0.99\n",
      "精度: 0.99\n",
      "召回率: 0.99\n",
      "F1得分: 0.99\n",
      "基于tfidf的支持向量机模型\n",
      "准确率: 0.99\n",
      "精度: 0.99\n",
      "召回率: 0.99\n",
      "F1得分: 0.99\n",
      "新闻报道单位: 其他新闻报道单位\n",
      "预测的新闻报道单位: 其他新闻报道单位\n",
      "新闻文本:\n",
      "中信（国际）电子科技有限公司推出新产品： 升职步步高、做生意发大财、连找情人都用的上，详情进入 网  址:  http://www.usa5588.com/ccc 电话：020-33770208   服务热线：013650852999 \n",
      "新闻报道单位: 其他新闻报道单位\n",
      "预测的新闻报道单位: 其他新闻报道单位\n",
      "新闻文本:\n",
      "您好！ 我公司有多余的发票可以向外代开！（国税、地税、运输、广告、海关缴款书）。 如果贵公司（厂）有需要请来电洽谈、咨询！ 联系电话: 013510251389  陈先生 谢谢 顺祝商祺! \n",
      "新闻报道单位: 其他新闻报道单位\n",
      "预测的新闻报道单位: 其他新闻报道单位\n",
      "新闻文本:\n",
      "如果您在信箱中不能正常阅读此邮件，请点击这里 \n",
      "新闻报道单位: 其他新闻报道单位\n",
      "预测的新闻报道单位: 其他新闻报道单位\n",
      "新闻文本:\n",
      "以下不能正确显示请点此 IFRAME: http://bbs.ewzw.com/viewthread.php?tid=3790 \n",
      "涉嫌抄袭新闻:\n",
      "新闻报道单位: 其他新闻报道单位\n",
      "预测的新闻报道单位: 新华社\n",
      "新闻文本:\n",
      "好记星跳楼价抛售,好记星E900+单词王,原价1280,现抛售价930元一台, 另赠价值168元口语革命, 我的QQ是：171770476  电话13957987096 旺旺是陈传兴 有意者请联系！！！！ \n",
      "新闻报道单位: 其他新闻报道单位\n",
      "预测的新闻报道单位: 新华社\n",
      "新闻文本:\n",
      "特价机票,查资料就上中华机票网去 \n",
      "新闻报道单位: 其他新闻报道单位\n",
      "预测的新闻报道单位: 新华社\n",
      "新闻文本:\n",
      "谢谢 \n",
      "新闻报道单位: 其他新闻报道单位\n",
      "预测的新闻报道单位: 新华社\n",
      "新闻文本:\n",
      "魏老师: 您好!demo那个服务器已经搭好. 您看是不是放在网站上的DEMO不应该再要用户名和密码了? 用户名:root 密码:wangbo IP:202.205.4.117 麻烦您啦~ 王博 \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics  #计算准确率 精度 召回率 F值\n",
    "import jieba\n",
    "import warnings\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "path = \"E:/pyPor/nlp_assignment-master/Lesson7-8/\"\n",
    "true_news_data_file = path +  \"news_classification/data/true_news_data.txt\"\n",
    "fake_news_data_file = path + \"news_classification/data/fake_news_data.txt\"\n",
    "stop_txt_file = \"E:/pyPor/nlp_assignment-master/Lesson7-8/stop/stopword.txt\"\n",
    "\n",
    "def bow_extractor(corpus, ngram_range=(1, 1)):\n",
    "    vectorizer = CountVectorizer(min_df=1, ngram_range=ngram_range)\n",
    "    features = vectorizer.fit_transform(corpus)\n",
    "    # print(vectorizer.get_feature_names())  #词表是以逗号、句号分割的\n",
    "    return vectorizer, features\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "def tfidf_transformer(bow_matrix):\n",
    "    transformer = TfidfTransformer(norm='l2',\n",
    "                                   smooth_idf=True,\n",
    "                                   use_idf=True)\n",
    "    tfidf_matrix = transformer.fit_transform(bow_matrix)\n",
    "    return transformer, tfidf_matrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def tfidf_extractor(corpus, ngram_range=(1, 1)):\n",
    "    vectorizer = TfidfVectorizer(min_df=1,\n",
    "                                 norm='l2',\n",
    "                                 smooth_idf=True,\n",
    "                                 use_idf=True,\n",
    "                                 ngram_range=ngram_range)\n",
    "    features = vectorizer.fit_transform(corpus) #每一个列表元素中的词语的词频（权重）一样\n",
    "    return vectorizer, features\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "stop_words = [line.strip() for line in open(stop_txt_file, 'r', encoding='utf-8-sig')]\n",
    "\n",
    
    "def get_data():\n",
    "    '''\n",
    "    获取数据 真新华社新闻取5000条，假新华社新闻取5001\n",
    "    :return: 文本数据，对应的labels\n",
    "    '''\n",
    "    with open(true_news_data_file, encoding=\"utf-8-sig\") as true_news_f, open(fake_news_data_file, encoding=\"utf-8-sig\") as fake_news_f:\n",
    "        true_news_data = true_news_f.readlines()\n",
    "        fake_news_data = fake_news_f.readlines()\n",
    "        true_news_label = np.ones(len(true_news_data)).tolist()  #创建一个列表5000个1.0 [1.0,1.0,1.0，……]\n",
    "        fake_news_label = np.zeros(len(fake_news_data)).tolist()  #创建一个列表5001个0.0 [0.0,0.0,0.0，……]\n",
    "        #1.0代表新华社，0.0代表其他新闻社\n",
    "        print(\"true_news_label len =\",len(true_news_label))\n",
    "        print(\"fake_news_label len =\",len(fake_news_label))\n",
    "        corpus = true_news_data + fake_news_data\n",
    "        labels = true_news_label + fake_news_label\n",
    "    return corpus, labels\n",
    "\n",
    "#过滤空文本，但本数据集中没有空文本\n",
    "def remove_empty_docs(corpus, labels):\n",
    "    filtered_corpus = []\n",
    "    filtered_labels = []\n",
    "    for doc, label in zip(corpus, labels):\n",
    "        if doc.strip():\n",
    "            filtered_corpus.append(doc)\n",
    "            filtered_labels.append(label) #len(filtered_corpus)=16266\n",
    "    return filtered_corpus, filtered_labels\n",
    "\n",
    "#划分数据集：将数据分为训练集和测试集\n",
    "def prepare_datasets(corpus, labels, test_data_proportion=0.3):\n",
    "    '''\n",
    "    :param corpus: 文本数据\n",
    "    :param labels: label数据\n",
    "    :param test_data_proportion:测试数据占比\n",
    "    :return: 训练数据,测试数据，训练label,测试label\n",
    "    '''\n",
    "    train_X, test_X, train_Y, test_Y = train_test_split(corpus, labels,test_size=test_data_proportion, random_state=42)\n",
    "    return train_X, test_X, train_Y, test_Y\n",
    "\n",
    "#数据预处理：分词、去数字、特殊字符（停用词后面处理去除）\n",
    "def deal_corpus(text):\n",
    "    text_with_spaces = ''\n",
    "    text = re.sub(r'\\d+', ' ', text)  # 去除数字\n",
    "    textcut = jieba.cut(text)\n",
    "    for word in textcut:\n",
    "        text_with_spaces += word + ' '\n",
    "    # print(text_with_spaces)\n",
    "    return text_with_spaces\n",
    "\n",
    "\n",
    "\n",
    "#计算得分\n",
    "def get_metrics(true_labels, predicted_labels):\n",
    "    print('准确率:', np.round(metrics.accuracy_score(true_labels, predicted_labels), 2))\n",
    "    print('精度:', np.round(metrics.precision_score(true_labels,predicted_labels,average='weighted'),2))\n",
    "    print('召回率:', np.round(metrics.recall_score(true_labels,predicted_labels,average='weighted'),2))\n",
    "    print('F1得分:', np.round(metrics.f1_score(true_labels,predicted_labels,average='weighted'),2))\n",
    "\n",
    "\n",
    "def train_predict_evaluate_model(classifier,train_features, train_labels,test_features, test_labels):\n",
    "    # build model\n",
    "    classifier.fit(train_features, train_labels)\n",
    "    # 用模型预测\n",
    "    predictions = classifier.predict(test_features)\n",
    "    # 评估模型效果\n",
    "    get_metrics(true_labels=test_labels,\n",
    "                predicted_labels=predictions)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    corpus, labels = get_data()  # 获取数据集\n",
    "    print(\"总的数据量:\", len(labels))\n",
    "\n",
    "    corpus, labels = remove_empty_docs(corpus, labels)\n",
    "\n",
    "    print('样本之一:', corpus[10])\n",
    "    print('样本的label:', labels[10])\n",
    "    label_name_map = [\"其他新闻报道单位\", \"新华社\"]\n",
    "    print('实际类型:labels[4999]=', label_name_map[int(labels[4999])],\"labels[10000]=\", label_name_map[int(labels[10000])]) #labels[0:4999]为1.0，labels[5000:10000]为0.0\n",
    "    \n",
    "\n",
    "    # 对数据进行划分 test_data_proportion=0.3 百分之30的数据作为测试数据\n",
    "    train_corpus, test_corpus, train_labels, test_labels = prepare_datasets(corpus,labels,test_data_proportion=0.3)\n",
    "\n",
    "    #数据预处理\n",
    "    norm_train_corpus = []\n",
    "    for text in train_corpus:\n",
    "        norm_train_corpus.append(deal_corpus(text))\n",
    "    norm_test_corpus = []\n",
    "    for text in test_corpus:\n",
    "        norm_test_corpus.append(deal_corpus(text))\n",
    "    print(len(norm_train_corpus),len(train_labels))\n",
    "    print(len(norm_test_corpus), len(test_labels))\n",
    "\n",
    "\n",
    "#朴素贝叶斯\n",
    "    # 计算单词权重\n",
    "    tf = TfidfVectorizer(stop_words=stop_words, max_df=0.5)\n",
    "\n",
    "    train_features = tf.fit_transform(norm_train_corpus)\n",
    "    # 上面fit过了，这里transform\n",
    "    test_features = tf.transform(norm_test_corpus)\n",
    "\n",
    "    # 多项式贝叶斯分类器\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    clf = MultinomialNB(alpha=0.001).fit(train_features, train_labels)\n",
    "    predicted_labels = clf.predict(test_features)\n",
    "\n",
    "    # 计算准确率\n",
    "    print('准确率为：', metrics.accuracy_score(test_labels, predicted_labels))\n",
    "\n",
    "    # 词袋模型特征\n",
    "    bow_vectorizer, bow_train_features = bow_extractor(norm_train_corpus)\n",
    "    bow_test_features = bow_vectorizer.transform(norm_test_corpus)\n",
    "\n",
    "    # tfidf 特征\n",
    "    tfidf_vectorizer, tfidf_train_features = tfidf_extractor(norm_train_corpus)\n",
    "    tfidf_test_features = tfidf_vectorizer.transform(norm_test_corpus)\n",
    "\n",
    "\n",
    "    # 训练分类器\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    from sklearn.linear_model import SGDClassifier\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "    mnb = MultinomialNB()  # 朴素贝叶斯\n",
    "    svm = SGDClassifier(loss='hinge', n_iter=100)  # 支持向量机\n",
    "    lr = LogisticRegression()  # 逻辑回归\n",
    "    knn = KNeighborsClassifier()#KNN\n",
    "\n",
    "    # 基于词袋模型的KNN模型\n",
    "    print(\"基于词袋模型特征的KNN模型\")\n",
    "    mnb_bow_predictions = train_predict_evaluate_model(classifier=knn,\n",
    "                                                       train_features=bow_train_features,\n",
    "                                                       train_labels=train_labels,\n",
    "                                                       test_features=bow_test_features,\n",
    "                                                       test_labels=test_labels)\n",
    "    # 基于词袋模型的多项朴素贝叶斯\n",
    "    print(\"基于词袋模型特征的贝叶斯分类器\")\n",
    "    mnb_bow_predictions = train_predict_evaluate_model(classifier=mnb,\n",
    "                                                       train_features=bow_train_features,\n",
    "                                                       train_labels=train_labels,\n",
    "                                                       test_features=bow_test_features,\n",
    "                                                       test_labels=test_labels)\n",
    "    print(mnb_bow_predictions)  #返回的预测结果：[0. 0. 1. ... 0. 1. 0.]\n",
    "    # 基于词袋模型特征的逻辑回归\n",
    "    print(\"基于词袋模型特征的逻辑回归\")\n",
    "    lr_bow_predictions = train_predict_evaluate_model(classifier=lr,\n",
    "                                                      train_features=bow_train_features,\n",
    "                                                      train_labels=train_labels,\n",
    "                                                      test_features=bow_test_features,\n",
    "                                                      test_labels=test_labels)\n",
    "\n",
    "   \n",
    "    print(\"基于词袋模型的支持向量机\")\n",
    "    svm_bow_predictions = train_predict_evaluate_model(classifier=svm,\n",
    "                                                       train_features=bow_train_features,\n",
    "                                                       train_labels=train_labels,\n",
    "                                                       test_features=bow_test_features,\n",
    "                                                       test_labels=test_labels)\n",
    "   \n",
    "    # 基于tfidf的KNN模型\n",
    "    print(\"基于tfidf的KNN模型\")\n",
    "    knn_tfidf_predictions = train_predict_evaluate_model(classifier=knn,\n",
    "                                                         train_features=tfidf_train_features,\n",
    "                                                         train_labels=train_labels,\n",
    "                                                         test_features=tfidf_test_features,\n",
    "                                                         test_labels=test_labels)\n",
    "   \n",
    "    print(\"基于tfidf的朴素贝叶斯模型\")\n",
    "    mnb_tfidf_predictions = train_predict_evaluate_model(classifier=mnb,\n",
    "                                                         train_features=tfidf_train_features,\n",
    "                                                         train_labels=train_labels,\n",
    "                                                         test_features=tfidf_test_features,\n",
    "                                                         test_labels=test_labels)\n",
    "    print(\"基于tfidf的逻辑回归模型\")\n",
    "    lr_tfidf_predictions = train_predict_evaluate_model(classifier=lr,\n",
    "                                                        train_features=tfidf_train_features,\n",
    "                                                        train_labels=train_labels,\n",
    "                                                        test_features=tfidf_test_features,\n",
    "                                                        test_labels=test_labels)\n",
    "   \n",
    "\n",
    "    # 基于tfidf的支持向量机模型\n",
    "    print(\"基于tfidf的支持向量机模型\")\n",
    "    svm_tfidf_predictions = train_predict_evaluate_model(classifier=svm,\n",
    "                                                         train_features=tfidf_train_features,\n",
    "                                                         train_labels=train_labels,\n",
    "                                                         test_features=tfidf_test_features,\n",
    "                                                         test_labels=test_labels)\n",
    "    \n",
    "    num = 0\n",
    "    for document, label, predicted_label in zip(test_corpus, test_labels, svm_tfidf_predictions):\n",
    "        if label == 0 and predicted_label == 0:\n",
    "            print('新闻报道单位:', label_name_map[int(label)])\n",
    "            print('预测的新闻报道单位:', label_name_map[int(predicted_label)])\n",
    "            print('新闻文本:')\n",
    "            print(re.sub('\\n', ' ', document))\n",
    "\n",
    "            num += 1\n",
    "            if num == 4:\n",
    "                break\n",
    "    #如果我们预测的是新华社的新闻，但是标签缺不是新华社，我们就说这篇新闻是抄袭新华社的\n",
    "    print(\"涉嫌抄袭新闻:\")\n",
    "    num = 0\n",
    "    for document, label, predicted_label in zip(test_corpus, test_labels, svm_tfidf_predictions):\n",
    "        if label == 0 and predicted_label == 1:\n",
    "            print('新闻报道单位:', label_name_map[int(label)])\n",
    "            print('预测的新闻报道单位:', label_name_map[int(predicted_label)])\n",
    "            print('新闻文本:')\n",
    "            print(re.sub('\\n', ' ', document))\n",
    "\n",
    "            num += 1\n",
    "            if num == 4:\n",
    "                break\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
